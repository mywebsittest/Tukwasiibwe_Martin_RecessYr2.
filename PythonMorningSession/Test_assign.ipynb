{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 37,
     "status": "error",
     "timestamp": 1711369776511,
     "user": {
      "displayName": "Jeff Geoff",
      "userId": "07242922224712335034"
     },
     "user_tz": -180
    },
    "id": "JVViZmJWlWYm",
    "outputId": "0e6fc0fa-22d1-4825-9da3-6ad4dd30321d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting otter-grader\n",
      "  Using cached otter_grader-5.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dill (from otter-grader)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jinja2 (from otter-grader)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nbformat (from otter-grader)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pandas in /home/martin/.local/lib/python3.10/site-packages (from otter-grader) (2.2.2)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from otter-grader) (5.4.1)\n",
      "Collecting python-on-whales (from otter-grader)\n",
      "  Using cached python_on_whales-0.71.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from otter-grader) (2.25.1)\n",
      "Collecting wrapt (from otter-grader)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting jupytext (from otter-grader)\n",
      "  Using cached jupytext-1.16.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from otter-grader) (8.0.3)\n",
      "Collecting fica>=0.3.1 (from otter-grader)\n",
      "  Using cached fica-0.3.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ipython in /home/martin/.local/lib/python3.10/site-packages (from otter-grader) (8.26.0)\n",
      "Collecting astunparse (from otter-grader)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting ipywidgets (from otter-grader)\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting ipylab (from otter-grader)\n",
      "  Using cached ipylab-1.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting nbconvert (from otter-grader)\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting docutils (from fica>=0.3.1->otter-grader)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sphinx (from fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinx-7.3.7-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse->otter-grader) (0.37.1)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/lib/python3/dist-packages (from astunparse->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/martin/.local/lib/python3.10/site-packages (from ipywidgets->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/martin/.local/lib/python3.10/site-packages (from ipywidgets->otter-grader) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets->otter-grader)\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.11 (from ipywidgets->otter-grader)\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/martin/.local/lib/python3.10/site-packages (from ipython->otter-grader) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython->otter-grader) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->otter-grader) (2.0.1)\n",
      "Collecting markdown-it-py>=1.0 (from jupytext->otter-grader)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdit-py-plugins (from jupytext->otter-grader)\n",
      "  Downloading mdit_py_plugins-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in /home/martin/.local/lib/python3.10/site-packages (from jupytext->otter-grader) (24.1)\n",
      "Collecting tomli (from jupytext->otter-grader)\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->otter-grader)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->otter-grader)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->otter-grader)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/martin/.local/lib/python3.10/site-packages (from nbconvert->otter-grader) (5.7.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert->otter-grader)\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->otter-grader)\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->otter-grader)\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->otter-grader)\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->otter-grader)\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->otter-grader)\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat->otter-grader)\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/martin/.local/lib/python3.10/site-packages (from pandas->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/martin/.local/lib/python3.10/site-packages (from pandas->otter-grader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->otter-grader) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/martin/.local/lib/python3.10/site-packages (from pandas->otter-grader) (2024.1)\n",
      "Collecting pydantic!=2.0.*,<3,>=1.9 (from python-on-whales->otter-grader)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m239.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from python-on-whales->otter-grader)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m494.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer>=0.4.1 (from python-on-whales->otter-grader)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->otter-grader)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/martin/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.4)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat->otter-grader)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat->otter-grader)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat->otter-grader)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat->otter-grader)\n",
      "  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/martin/.local/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert->otter-grader) (4.2.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=1.0->jupytext->otter-grader)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/martin/.local/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert->otter-grader) (8.6.2)\n",
      "Requirement already satisfied: wcwidth in /home/martin/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.13)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=2.0.*,<3,>=1.9->python-on-whales->otter-grader)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic!=2.0.*,<3,>=1.9->python-on-whales->otter-grader)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.4.1->python-on-whales->otter-grader)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.4.1->python-on-whales->otter-grader)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->otter-grader)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting sphinxcontrib-applehelp (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sphinxcontrib-qthelp (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting snowballstemmer>=2.0 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting babel>=2.9 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading Babel-2.15.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting alabaster~=0.7.14 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx->fica>=0.3.1->otter-grader)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/martin/.local/lib/python3.10/site-packages (from stack-data->ipython->otter-grader) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/martin/.local/lib/python3.10/site-packages (from stack-data->ipython->otter-grader) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/martin/.local/lib/python3.10/site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/martin/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/martin/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (6.4.1)\n",
      "Using cached otter_grader-5.5.0-py3-none-any.whl (159 kB)\n",
      "Using cached fica-0.3.1-py3-none-any.whl (12 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m73.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached ipylab-1.0.0-py3-none-any.whl (100 kB)\n",
      "Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m89.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m210.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jupytext-1.16.2-py3-none-any.whl (153 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m257.4/257.4 kB\u001b[0m \u001b[31m251.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m290.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_on_whales-0.71.0-py3-none-any.whl (165 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m353.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m355.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m385.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m397.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m483.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m518.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m498.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m420.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m309.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m309.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m387.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading mdit_py_plugins-0.4.1-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m454.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinx-7.3.7-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m308.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m226.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m202.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Babel-2.15.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m237.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m294.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m346.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m290.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m251.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m249.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m178.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m251.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m287.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: webencodings, snowballstemmer, fastjsonschema, wrapt, widgetsnbextension, tqdm, tomli, tinycss2, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, soupsieve, shellingham, rpds-py, pydantic-core, pandocfilters, mistune, mdurl, jupyterlab-widgets, jupyterlab-pygments, jinja2, imagesize, docutils, dill, defusedxml, bleach, babel, attrs, astunparse, annotated-types, alabaster, sphinx, referencing, pydantic, markdown-it-py, beautifulsoup4, rich, mdit-py-plugins, jsonschema-specifications, fica, typer, jsonschema, ipywidgets, python-on-whales, nbformat, ipylab, nbclient, jupytext, nbconvert, otter-grader\n",
      "Successfully installed alabaster-0.7.16 annotated-types-0.7.0 astunparse-1.6.3 attrs-23.2.0 babel-2.15.0 beautifulsoup4-4.12.3 bleach-6.1.0 defusedxml-0.7.1 dill-0.3.8 docutils-0.21.2 fastjsonschema-2.20.0 fica-0.3.1 imagesize-1.4.1 ipylab-1.0.0 ipywidgets-8.1.3 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 jupyterlab-pygments-0.3.0 jupyterlab-widgets-3.0.11 jupytext-1.16.2 markdown-it-py-3.0.0 mdit-py-plugins-0.4.1 mdurl-0.1.2 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 otter-grader-5.5.0 pandocfilters-1.5.1 pydantic-2.7.4 pydantic-core-2.18.4 python-on-whales-0.71.0 referencing-0.35.1 rich-13.7.1 rpds-py-0.18.1 shellingham-1.5.4 snowballstemmer-2.2.0 soupsieve-2.5 sphinx-7.3.7 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10 tinycss2-1.3.0 tomli-2.0.1 tqdm-4.66.4 typer-0.12.3 webencodings-0.5.1 widgetsnbextension-4.0.11 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize Otter\n",
    "!pip install otter-grader\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook(\"Test_assign.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5.0\n"
     ]
    }
   ],
   "source": [
    "print(otter.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DroRwx3ENZ"
   },
   "source": [
    "## DSA 2024 Summer School Admittance Check\n",
    "\n",
    "Thanks for your interest in attending DSA 2024 Nyeri, Kenya. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School. See you in Nyeri!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7Upwjh9U3ENa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import otter\n",
    "\n",
    "#grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6ibmmx8r3ENc"
   },
   "source": [
    "**Question 1:** write a function `isValid(s)` that takes as argument a string s containing a sequence of parenthesis '(', ')', '{', '}', '[' and ']', and  determines if the input is valid. A input string is valid if for every open parenthensis there is a close one and parenthesis is well-formed. e.g  \"(){}[]\" is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CWjGPqaO3ENc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def isValid(s):\n",
    "    stack = []\n",
    "    mapping = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n",
    "    \n",
    "    for char in s:\n",
    "        if char in mapping:\n",
    "            top_element = stack.pop() if stack else '#'\n",
    "            if mapping[char] != top_element:\n",
    "                return False\n",
    "        else:\n",
    "            stack.append(char)\n",
    "    \n",
    "    return not stack\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yi1Xx4UllWYs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! 笨ｨ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ntYqVxEQ3ENd"
   },
   "source": [
    "**Question 2:** Given a paragraph as a string, write a function that return the number of character with odd frequencies. E.g The paragraph ``DSA 2024 Nyeri`` has *10* characters with odd frequencies. i.e the entire frequency count is given as {' ': 2, '2': 2, 'D': 1, 'S': 1, 'A': 1, '0': 1, '4': 1, 'N': 1, 'y': 1, 'e': 1, 'r': 1, 'i': 1}) and there are *10* characters with odd frequences. So the function should return *10*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LlZ8GC4J3ENe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def oddFrequencyCounter(theParagraph):\n",
    "# Dictionary to store the frequency of each character\n",
    "    frequency = {}\n",
    "    \n",
    "    # Count the frequency of each character in the paragraph\n",
    "    for char in paragraph:\n",
    "        if char in frequency:\n",
    "            frequency[char] += 1\n",
    "        else:\n",
    "            frequency[char] = 1\n",
    "    \n",
    "    # Count the number of characters with odd frequencies\n",
    "    odd_count = 0\n",
    "    for count in frequency.values():\n",
    "        if count % 2 != 0:\n",
    "            odd_count += 1\n",
    "    \n",
    "    return odd_count\n",
    "\n",
    "# Example usage\n",
    "paragraph = \"Hello\"\n",
    "print(oddFrequencyCounter(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BhzphhailWYt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! 笨ｨ</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UIijW8polWYt"
   },
   "source": [
    "**Question 3:** Write an infinite generator function `odd_squares_sum` that yields the sum of square of odd numbers. e.g $1^2 + 3^2 + 5^2 + ...$ up to a ``limit``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I50ccd1SJMn4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def odd_squares_sum(limit):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "40vFKLm4lWYu"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hucvAvprJMn5"
   },
   "source": [
    "**Question 4:** Using the `odd_squares_sum` generator defined above, create a list of sum of squares up to a limit of $20$ and store the results in a numpy.array variable called `oddSumList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLHoBNERJMn5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "O2fs215YlWYv"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9PpnMsGpJMn5"
   },
   "source": [
    "**Question 5:** Compute the element-wise remainder of ``oddSumList`` when divided by $5$ and merge it with ``oddSumList``. The final output stored in the variable `mergedList` should be in the form of a list of tupples e.g ``[(1,1), (4,9), (0,25), ...]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDWWh3vQJMn5",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "k_Xjmvz3lWYw"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Elpmq1BrlWYx"
   },
   "source": [
    "**Question 6:**  Write a function `greatest_common_divisor` that takes two inputs `a` and `b` and returns the greatest common divisor of the two numbers. E.g. input `(10, 15)` would return `5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Nv669sgUlWYx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def greatest_common_divisor(a, b):\n",
    "    while b:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "# Example usage:\n",
    "print(greatest_common_divisor(10, 15))  # Output should be 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yfPxbTRvlWYx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed! 沍</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7y4uAEvTlWYx"
   },
   "source": [
    "**Question 7:**  Write a function `get_3_nearest` that takes in a point of interest ``pt`` and a **list** of points ``ptlist``  and returns a list of 3 nearest points from the point of interest ``pt``. Assume the distance between any two point is defined by the `L1-norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eVRG_iYKlWYy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3), (2, 3), (5, 5)]\n"
     ]
    }
   ],
   "source": [
    "def l1_distance(pt1, pt2):\n",
    "    return sum(abs(a - b) for a, b in zip(pt1, pt2))\n",
    "\n",
    "def get_3_nearest(pt, ptlist):\n",
    "    sorted_points = sorted(ptlist, key=lambda point: l1_distance(pt, point))\n",
    "    return sorted_points[:3]\n",
    "\n",
    "# Example usage:\n",
    "pt = (3, 4)\n",
    "ptlist = [(2, 3), (5, 5), (4, 6), (7, 2), (1, 1), (3, 3)]\n",
    "nearest_points = get_3_nearest(pt, ptlist)\n",
    "print(nearest_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TJTLyKpblWYy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed! 汳ｯ</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Tv6dcD3glWYy"
   },
   "source": [
    "**Question 8:**  Write a function `diagonal_vector(M)` that returns a **numpy** array of the list of **absolute** values of the main diagonal entries in the matrix $M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ypwKDudclWYy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 9]\n"
     ]
    }
   ],
   "source": [
    "def diagonal_vector(M):\n",
    "    # Extract the main diagonal entries using np.diagonal\n",
    "    main_diagonal = np.diagonal(M)\n",
    "    # Compute the absolute values of the main diagonal entries\n",
    "    abs_diagonal = np.abs(main_diagonal)\n",
    "    return abs_diagonal\n",
    "\n",
    "# Example usage:\n",
    "M = np.array([[1, -2, 3], [-4, 5, -6], [7, -8, 9]])\n",
    "result = diagonal_vector(M)\n",
    "print(result)  # Output: [1 5 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pNS5UGzhlWYz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed! 笨ｨ</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gswRlZmblWYz"
   },
   "source": [
    "**Question 9:**  Write a function `flatten_reverse_lists` that takes in a list of lists and outputs a **reverse** sorted list of elements of sublists of the input list (confusing right?) <br>\n",
    "Example: given `flatten_reverse_lists([[2,13,44], [6,7]])` it should return `[2,6,7,13,44]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g14foUPZlWYz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_reverse_lists(superlist):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AXJgWszQlWY0"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e5hEhB9DlWY0"
   },
   "source": [
    "**Question 9:** Create a DataFrame mirroring the table below and assign this to `data`.\n",
    "\n",
    "| flavor | scoops | price |\n",
    "|-----|-----|-----|\n",
    "| white chocolate | 1 | 2 |\n",
    "| vanilla | 1 | 1.5 |\n",
    "| dark chocolate | 2 | 3 |\n",
    "| strawberry | 1 | 2 |\n",
    "| strawberry | 3 | 4 |\n",
    "| vanilla | 2 | 2 |\n",
    "| mint | 1 | 4 |\n",
    "| mint | 2 | 5 |\n",
    "| white chocolate | 3 | 2 |\n",
    "| dark chocolate | 3 | 3 |\n",
    "| white chocolate | 2 | 2 |\n",
    "| dark chocolate | 5 | 3 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1Q9SHPqlWY0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vCrDbFGJlWY1"
   },
   "source": [
    "**Question 10:** Do the following to the dataframe:\n",
    "* Create a new collumn ``total_price`` whose value is equal to $scoops * price$*\n",
    "* Write a function ``groupStatistics(data, groupValue)``. Internally, this function groups ``data``  by ``flavor`` and then returns statistics of a given grouped item ``groupValue`` indexed on the ``total_price`` columns. The statistics is a numpy array contains ``[mean, media, min, max, std]`` of the ``total_price`` column. The ``std`` should be rounded to 2 **decimal places**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzlvoEnTlWY1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j9S-jXqTlWY1"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cZpMZvKvlWY2"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Download the exported ZIP. Take note of the ZIP number and proceed to fill the summer school form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f0WDkVsUlWY2"
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjEBf1KPlWY2"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 1\n>>> \n>>> def test_isValid(isValid):\n...     assert isValid('{[()]}}') == False\n>>> test_isValid(isValid)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> \n>>> def test_isValid(isValid):\n...     assert isValid('') == True\n>>> test_isValid(isValid)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> \n>>> def test_isValid(isValid):\n...     assert isValid('(){}[]') == True\n>>> test_isValid(isValid)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 1\n>>> np.testing.assert_array_equal(groupStatistics(data, 'strawberry'), [7.0, 7.0, 2.0, 7.07])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_array_equal(groupStatistics(data, 'dark chocolate'), [10.0, 9.0, 6.0, 4.58])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_array_equal(groupStatistics(data, 'white chocolate'), [4.0, 4.0, 2.0, 2.0])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_array_equal(groupStatistics(data, 'vanilla'), [2.75, 2.75, 1.5, 1.77])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_array_equal(groupStatistics(data, 'mint'), [7.0, 7.0, 4.0, 4.24])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 1\n>>> \n>>> def test_oddFrequencyCounter(oddFrequencyCounter):\n...     paragraph = 'DSA 2024 Nyeri'\n...     assert oddFrequencyCounter(paragraph) == 10\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> \n>>> def test_oddFrequencyCounter(oddFrequencyCounter):\n...     paragraph = \"The following is sample text I used to practice special characters using keybr.com: 112233445566778899 Saturn V rocket's first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage's five F-1 rocket engines ignite and produce 7.5 million pounds of thrust. To replace those goofy quantities with the far less retarded metric system (even though liters are considered part of the metric system they are the same as cubic deci-meters) you would say 770 cubic meters of kerosene {abbreviated as m3} and 1,204 m3 of liquid O2 [O2 is the symbol for oxygen]. We would also say it produced 33,600,000 newtons of force <abbreviated as N>. To add scientific notation {a way of writing numbers that allows you to write only as many digits of specificity as you would like} you can write 7.7 * 10 ^ 2 m3 of kerosene 1.204 * 10 ^ 3 m3 of O2 and 3.3 * 10 ^ 7 newtons.\"\n...     assert oddFrequencyCounter(paragraph) == 40\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> \n>>> def test_oddFrequencyCounter(oddFrequencyCounter):\n...     paragraph = 'Data Science Africa in collaboration with The Swiss Federal Department of Foreign Affairs (FDFA), ETH Zurich, EPFL, the European Laboratory for Learning and Intelligent Systems (ELLIS), the Swiss National Computing Centre (CSCS), and the LUMI consortium launched the International Computation and AI Network (ICAIN) at the World Economic Forum (WEF) 2024 in Davos. Its mission is to develop AI technologies that benefit society as a whole, as well as being accessible to all and sustainable, thereby helping to reduce global inequality.'\n...     assert oddFrequencyCounter(paragraph) == 20\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 4\n>>> theGen = odd_squares_sum(12)\n>>> assert next(theGen) == 1\n>>> assert next(theGen) == 9\n>>> assert next(theGen) == 25\n>>> assert next(theGen) == 49\n>>> assert next(theGen) == 81\n>>> assert next(theGen) == 121\n>>> del theGen\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 2\n>>> assert (oddSumList == np.array([1, 9, 25, 49, 81, 121, 169, 225, 289, 361])).all()\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 2\n>>> assert isinstance(oddSumList, np.ndarray)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 2\n>>> assert mergedList == [(1, 1), (4, 9), (0, 25), (4, 49), (1, 81), (1, 121), (4, 169), (0, 225), (4, 289), (1, 361)]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 1\n>>> np.testing.assert_equal(greatest_common_divisor(10, 15), 5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_equal(greatest_common_divisor(15, 19), 1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_equal(greatest_common_divisor(100, 105), 5)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 8,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 2\n>>> np.testing.assert_equal(get_3_nearest((3, 8), [(9, 3), (8, 5), (7, 6)]), [(7, 6), (8, 5), (9, 3)])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 2\n>>> np.testing.assert_equal(get_3_nearest((12, 8), [(5, 9), (9, 1), (2, 4), (13, 9), (10, 12)]), [(13, 9), (10, 12), (5, 9)])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 2\n>>> np.testing.assert_equal(get_3_nearest((5, 8), [(5, 9), (9, 1), (2, 4), (13, 9), (10, 12)]), [(5, 9), (2, 4), (13, 9)])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 2\n>>> np.testing.assert_array_equal(diagonal_vector([[1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], [17, 18, 19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30, 31, 32], [33, 34, 35, 36, 37, 38, 39, 40], [41, 42, 43, 44, 45, 46, 47, 48], [49, 50, 51, 52, 53, 54, 55, 56], [57, 58, 59, 60, 61, 62, 63, 64]]), [1, 10, 19, 28, 37, 46, 55, 64])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 2\n>>> assert isinstance(diagonal_vector([[1, 2], [3, 4]]), np.ndarray)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> points: 1\n>>> np.testing.assert_equal(flatten_reverse_lists([[2, 13, 44], [6, 7]]), [44, 13, 7, 6, 2])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> points: 1\n>>> np.testing.assert_equal(flatten_reverse_lists([[2], [61, 34, 5, 8, 9]]), [61, 34, 9, 8, 5, 2])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
